{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Universidad del Valle de Guatemala  \n",
        "Reinforcement Learning  \n",
        "Alberto Suriano  \n",
        "\n",
        "Hoja de trabajo 1  \n",
        "Marlon Hernández - 15177  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1 - Preguntas Teóricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Responda a cada de las siguientes preguntas de forma clara y lo más completamente posible.\n",
        "1. **Describa cada uno de los siguientes elementos de Reinforcement Learning.**  \n",
        "    a. **Policy**\n",
        "    Una política es el conjunto de reglas o condiciones que utiliza un agente de aprendizaje para decidir qué acción debe tomar en un estado dado. Estas reglas mapean estados a acciones, y puede ser determinista o estocástica. En una política determinista, para un estado específico siempre se elige la misma acción, mientras que en una política estocástica, la acción se elige de acuerdo a una distribución de probabilidad.\n",
        "\n",
        "    b. **Señal de Recompensa**\n",
        "    Una señal de recompensa es la retroalimentación numérica que recibe el agente desde el entorno después de realizar una acción. Esta recompensa informa al agente sobre el valor de sus acciones en términos de que tan bueno o malo fue el resultado de la acción tomada en ese estado.\n",
        "\n",
        "    c. **Función Valor**\n",
        "    La función valor es una estimación de la recompensa que se recibe realizando las acciones en esos estados según una política particular. Esto permite escoger la mejor acción para obtener el estado con mayor valor.\n",
        "\n",
        "    d. **Modelo del ambiente**\n",
        "    El modelo del ambiente es una representación del comportamiento del entorno. Este modelo predice las transiciones de estados y las recompensas.\n",
        "\n",
        "2. **Cuando decimos que el objetivo de un agente de aprendizaje por refuerzo es maximizar una señal de recompensa numérica, ¿estamos insistiendo en que el agente tenga que alcanzar realmente el objetivo de máxima recompensa? ¿Por qué?**  \n",
        "   El objetivo del el agente es aprender una política que en promedio maximice la suma acumulada de recompensas a lo largo del tiempo. Esto se debe a que la maximización puede ser un proceso a largo plazo que implica equilibrar exploración y explotación, lo cual puede que no siempre se esté tomando la acción con la mayor recompensa inmediata.\n",
        " \n",
        "3. **Explique el gráfico de Reinforcement Learning visto en clase. Brinde un ejemplo de su interés**  \n",
        "    En un momento dado dentro de un entorno, el agente se encuentra en un estado, este agente toma acciones basadas en una política, esta acción genera una recompensa al agente para evaluar la siguiente acción a tomar ahora que el agente se encuentra en un estado nuevo.\n",
        "\n",
        "    Por ejemplo un robot que debe aprender a navegar por una casa para llegar al punto de recarga. El estado sería la ubicación y orientación del robot, una acción sería moverse en una dirección específica, la recompensa sería positiva al acercarse al cargador y negativa al chocar con objetos, y el nuevo estado sería la nueva ubicación y orientación después del movimiento. \n",
        "    \n",
        "4. **¿Qué pasaría si al entrenar un agente nos enfocamos en la “exploración”? ¿Y en el caso de enfocarnos únicamente en “exploración”?**  \n",
        "    Si al entrenar un agente nos enfocamos solo en la exploración, el agente probará muchas acciones diferentes para descubrir más del entorno. Esto puede ayudar a encontrar mejores políticas, especialmente en entornos complejos y desconocidos, pero puede ser ineficiente ya que el agente también podría realizar muchas acciones subóptimas. Si nos enfocamos únicamente en la explotación, el agente siempre tomará las acciones que actualmente considera las mejores basadas en su conocimiento actual. Esto puede llevar a resultados rápidos y eficaces en el corto plazo, pero también puede causar que el agente se quede atrapado en un óptimo local y no descubra estrategias mejores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Referencias\n",
        "* https://deeplizard.com/learn/video/nyjbcRQ-uQ8\n",
        "* https://aws.amazon.com/es/what-is/reinforcement-learning/\n",
        "* https://www.spiceworks.com/tech/artificial-intelligence/articles/what-is-reinforcement-learning/\n",
        "* https://towardsdatascience.com/reinforcement-learning-101-e24b50e1d292"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
